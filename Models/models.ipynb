{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data import and basic summary\n",
    "np.random.seed(49)\n",
    "DashData = pd.read_csv(\"C:/Users/Zach/Documents/GitHub/DoorDashModels/Data/historical_data.csv\")\n",
    "DashData.head(10)\n",
    "DashData.info()\n",
    "DashData.describe()\n",
    "print(\"Percentange of missing value % :\",DashData.isna().mean().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the target variable for models\n",
    "from datetime import datetime\n",
    "DashData['created_at'] = pd.to_datetime(DashData['created_at'])\n",
    "DashData[\"actual_delivery_time\"] = pd.to_datetime(DashData[\"actual_delivery_time\"])\n",
    "DashData[\"Total_Delivery_Duration\"] = (DashData[\"actual_delivery_time\"] - DashData[\"created_at\"]).dt.total_seconds()\n",
    "\n",
    "DashData.head(10)\n",
    "#New feature creations\n",
    "DashData['Estimated_non_prep_duration'] = DashData[\"estimated_store_to_consumer_driving_duration\"] + DashData[\"estimated_order_place_duration\"]\n",
    "DashData['BusyDriverRatio'] = DashData[\"total_busy_dashers\"] / DashData[\"total_onshift_dashers\"]\n",
    "#Time features\n",
    "DashData['Months'] = DashData['created_at'].dt.month\n",
    "DashData['Quarter'] = DashData['created_at'].dt.quarter\n",
    "#aggregate features\n",
    "DashData['TotalOrderPerStore'] = DashData.groupby('store_id')['total_items'].transform('sum')\n",
    "DashData['OrderValuePerStore'] = DashData.groupby('store_id')['total_items'].transform('mean')\n",
    "DashData['OrderCountMonthsPerStore'] = DashData.groupby('Months')['total_items'].transform('sum')\n",
    "\n",
    "#simple store metrics\n",
    "avg_by_category= DashData.groupby('store_primary_category')['subtotal'].mean() / 100\n",
    "print(\"Average subtotals per store category in dollars:\")\n",
    "print(avg_by_category)\n",
    "std_by_category = DashData.groupby('store_primary_category')['subtotal'].std() / 100\n",
    "print(\"\\nStandard deviation of subtotals per store category in dollars:\")\n",
    "print(std_by_category)\n",
    "print(\"Average order delivery time in minutes:\")\n",
    "print(f\"{DashData['Total_Delivery_Duration'].mean()/60:.2f}\")\n",
    "\n",
    "DashData.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary for store categories to fill the null categories using the most common category -- could be better way to do with with SME\n",
    "store_id_unique = DashData[\"store_id\"].unique().tolist()\n",
    "store_id_and_category = {store_id: DashData[DashData.store_id == store_id].store_primary_category.mode() \n",
    "                         for store_id in store_id_unique}\n",
    "def fill(store_id):\n",
    "    \"\"\"Return primary store category from the dictionary\"\"\"\n",
    "    try:\n",
    "        return store_id_and_category[store_id].values[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# fill null values\n",
    "DashData[\"nan_free_store_primary_category\"] = DashData.store_id.apply(fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies\n",
    "OrderProtocalDummies =pd.get_dummies(DashData.order_protocol, dtype=int)\n",
    "OrderProtocalDummies = OrderProtocalDummies.add_prefix('OrderProtocal_')\n",
    "#checking\n",
    "OrderProtocalDummies.head()\n",
    "MarketIdDummies = pd.get_dummies(DashData.market_id, dtype=int)\n",
    "MarketIdDummies = MarketIdDummies.add_prefix('MarketId_')\n",
    "#checking\n",
    "MarketIdDummies.head()\n",
    "StoreCategoryDummies = pd.get_dummies(DashData.nan_free_store_primary_category, dtype=int)\n",
    "StoreCategoryDummies = StoreCategoryDummies.add_prefix('StoreCategory_')\n",
    "#checking\n",
    "StoreCategoryDummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with infinite max value:\n",
      "Index(['BusyDriverRatio'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# defining the intial train DF\n",
    "train_df = DashData.drop(columns = [\"created_at\", \"market_id\", \"store_id\", \"store_primary_category\", \"actual_delivery_time\",\"nan_free_store_primary_category\", \"order_protocol\"])\n",
    "train_df.head()\n",
    "#merging the dummies to train\n",
    "train_df = pd.concat([train_df, OrderProtocalDummies, MarketIdDummies, StoreCategoryDummies], axis=1)\n",
    "#checking\n",
    "train_df.head()\n",
    "#seeing which fetures that have infinte max value -- could be issue for models\n",
    "if np.isinf(train_df).any().any():\n",
    "    print(\"Features with infinite max value:\")\n",
    "    print(train_df.columns[np.isinf(train_df).any()])\n",
    "else:\n",
    "    print(\"No infinite values in the dataset\")\n",
    "#ensuring dtype synergy\n",
    "train_df = train_df.astype(\"Float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    197428.0\n",
       "mean     0.949777\n",
       "std      0.385194\n",
       "min         -13.0\n",
       "25%      0.846154\n",
       "50%      0.949778\n",
       "75%           1.0\n",
       "max          31.0\n",
       "Name: BusyDriverRatio, dtype: Float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing infinite values in BusyDriverRatio with NaN then with the mean of the column\n",
    "train_df[\"BusyDriverRatio\"] = train_df[\"BusyDriverRatio\"].replace([np.inf, -np.inf], np.nan)\n",
    "train_df[\"BusyDriverRatio\"] = train_df[\"BusyDriverRatio\"].fillna(train_df[\"BusyDriverRatio\"].mean())\n",
    "#checking\n",
    "train_df[\"BusyDriverRatio\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Task (3/20): Removing Redundant and Potential Collinear Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
